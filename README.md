# ğŸ§  Task 2 â€“ Exploratory Data Analysis (EDA)

This task involves performing an in-depth exploration of the dataset provided by the eCommerce platform to uncover patterns, assess data quality, and derive insights that will guide feature engineering and model development for the credit scoring model.

---

## ğŸ“ File Location

- ğŸ“„ Raw dataset: `data/raw/data.csv`
- ğŸ“” Notebook: `notebooks/1.0-eda.ipynb`
- ğŸ§  Source functions: `src/data_processing.py`
- ğŸ’¾ Processed output: `data/processed/data_cleaned.csv`

---

## ğŸ¯ Objectives

- Understand the structure and contents of the dataset
- Visualize distributions of numerical and categorical features
- Analyze correlations between variables
- Identify and handle missing values and outliers
- Extract actionable insights for feature engineering

---

## ğŸ›  Steps Performed

1. **Data Overview**
   - Checked shape, column types, and sample records
   - Found 95,662 transactions across 16 features
   - All data types and encodings verified

2. **Summary Statistics**
   - Computed mean, median, std, and percentiles for numeric features
   - Identified skewness and scale differences (especially in `Amount`, `Value`)

3. **Visual Analysis**
   - Plotted histograms of all numeric features
   - Visualized categorical feature distributions with bar plots
   - Generated correlation matrix heatmap
   - Created box plots to observe outliers

4. **Missing Values**
   - Verified no missing values in the dataset

5. **Outlier Detection**
   - Detected significant outliers in `Amount`, `Value`, and `PricingStrategy`

---

## ğŸ” Key Insights

| Insight | Description |
|--------|-------------|
| ğŸ“‰ `FraudResult` is highly imbalanced | Only ~0.2% of samples are fraud (1) â€” needs special treatment in modeling. |
| ğŸ’° `Amount` and `Value` have extreme outliers and skewed distribution | Suggests log transformation or robust modeling. |
| ğŸŒ `CountryCode` is constant (`256`) | Can be safely dropped (no variance). |
| ğŸ”„ Behavioral features are needed | Frequency, recency, and spend patterns likely more predictive than raw transaction values. |

---

## ğŸ“¦ Output

- âœ… Cleaned and structured dataset saved to:  
  `data/processed/data_cleaned.csv`

- âœ… All plots saved and also visualized inline in the notebook.

---

## ğŸ§  Next Steps

- Engineer customer-level behavioral features (e.g., RFM)
- Encode categorical features
- Prepare training-ready dataset for modeling
